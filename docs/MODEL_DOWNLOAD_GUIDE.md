# Whisper Model Download Guide

## üì¶ T·ªïng quan

D·ª± √°n s·ª≠ d·ª•ng Whisper models ƒë·ªÉ chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i th√†nh vƒÉn b·∫£n. Models ƒë∆∞·ª£c l∆∞u trong MinIO v√† t·ª± ƒë·ªông download khi c·∫ßn.

## üéØ V·∫•n ƒë·ªÅ ƒë√£ gi·∫£i quy·∫øt

1. **Tr∆∞·ªõc ƒë√¢y:**
   - Model files (>100MB) kh√¥ng th·ªÉ push l√™n GitHub
   - Ph·∫£i commit binary files v√†o Git
   - Docker images r·∫•t n·∫∑ng
   - Model files missing khi build Docker

2. **Gi·∫£i ph√°p hi·ªán t·∫°i:**
   - Models l∆∞u trong MinIO (object storage)
   - T·ª± ƒë·ªông download t·ª´ MinIO khi c·∫ßn
   - Docker images nh·∫π h∆°n
   - Kh√¥ng commit model files v√†o Git

---

## üì• C√°ch Download Models

### Option 1: T·ª± ƒë·ªông download (Recommended)

Models s·∫Ω t·ª± ƒë·ªông download t·ª´ MinIO khi:
- Worker service kh·ªüi ƒë·ªông (trong Docker)
- Transcription ƒë∆∞·ª£c g·ªçi l·∫ßn ƒë·∫ßu (trong code)

**Trong Docker:**
```bash
docker-compose up worker
# ‚Üí Entrypoint script t·ª± ƒë·ªông download model
```

**Trong code:**
```python
# worker/transcriber.py t·ª± ƒë·ªông download n·∫øu model ch∆∞a c√≥
transcriber = WhisperTranscriber()
transcriber.transcribe(audio_path, model="medium")  # Auto-download n·∫øu thi·∫øu
```

### Option 2: Download th·ªß c√¥ng

**Download t·∫•t c·∫£ models:**
```bash
python scripts/setup_models.py
```

**Download model c·ª• th·ªÉ:**
```bash
# Download ch·ªâ model 'medium'
python scripts/setup_models.py medium

# Download nhi·ªÅu models
python scripts/setup_models.py tiny base medium
```

### Option 3: Skip download (Development)

N·∫øu b·∫°n ƒë√£ c√≥ model files local:
```bash
# ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng
export SKIP_MODEL_DOWNLOAD=true

# Ho·∫∑c trong Docker
docker run -e SKIP_MODEL_DOWNLOAD=true ...
```

---

## Available Models

| Model | Size | Quality | Speed | Use Case |
|-------|------|---------|-------|----------|
| `tiny` | 75 MB | ‚≠ê | ‚ö°‚ö°‚ö°‚ö°‚ö° | Testing, demo |
| `base` | 142 MB | ‚≠ê‚≠ê | ‚ö°‚ö°‚ö°‚ö° | Quick transcription |
| `small` | 466 MB | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | Balanced |
| `medium` | 1.5 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | Production (Vietnamese) |
| `large` | 2.9 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö° | Best quality |

**Default model:** `medium` (best for Vietnamese)

---

## üê≥ Docker Setup

### 1. Upload Models to MinIO

Tr∆∞·ªõc ti√™n, upload models l√™n MinIO:

```bash
# Upload model files to MinIO bucket
# Bucket: stt-audio-files (ho·∫∑c theo config)
# Path: whisper-models/ggml-{model}.bin

# V√≠ d·ª• v·ªõi MinIO client:
mc cp whisper/models/ggml-medium.bin minio/stt-audio-files/whisper-models/
```

### 2. Build Docker Image

```bash
# Build worker image (kh√¥ng copy models)
docker build -f cmd/worker/Dockerfile -t stt-worker:latest .
```

**Image size:**
- Tr∆∞·ªõc: ~4-5GB (with models)
- Sau: ~1-2GB (without models)

### 3. Run with Docker Compose

```yaml
# docker-compose.yml
services:
  worker:
    build:
      context: .
      dockerfile: cmd/worker/Dockerfile
    environment:
      # MinIO settings
      MINIO_ENDPOINT: minio:9000
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
      MINIO_BUCKET: stt-audio-files
      
      # Model download settings
      SKIP_MODEL_DOWNLOAD: "false"  # Set to "true" to skip
      MODEL_TO_DOWNLOAD: "medium"   # Which model to download
      
    volumes:
      # Optional: Mount models directory to persist downloads
      - ./whisper/models:/app/whisper/models
```

### 4. Start Services

```bash
docker-compose up -d
```

**Lu·ªìng ho·∫°t ƒë·ªông:**
1. Worker container starts
2. Entrypoint script ch·∫°y
3. Check n·∫øu model exists
4. N·∫øu kh√¥ng ‚Üí download t·ª´ MinIO
5. Start worker process

---

## üîß Configuration

### Environment Variables

```bash
# Model download control
SKIP_MODEL_DOWNLOAD=false          # true = skip download
MODEL_TO_DOWNLOAD=medium           # Model to download at startup

# Whisper paths
WHISPER_EXECUTABLE=./whisper/bin/whisper-cli
WHISPER_MODELS_DIR=./whisper/models

# MinIO settings
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=stt-audio-files
```

### Model Storage in MinIO

**MinIO structure:**
```
bucket: stt-audio-files/
  ‚îú‚îÄ‚îÄ uploads/              # Audio uploads
  ‚îú‚îÄ‚îÄ results/              # Transcription results
  ‚îî‚îÄ‚îÄ whisper-models/       # Whisper models
      ‚îú‚îÄ‚îÄ ggml-tiny.bin
      ‚îú‚îÄ‚îÄ ggml-base.bin
      ‚îú‚îÄ‚îÄ ggml-small.bin
      ‚îú‚îÄ‚îÄ ggml-medium.bin
      ‚îî‚îÄ‚îÄ ggml-large.bin
```

---

## Usage Examples

### Example 1: Local Development

```bash
# 1. Upload models to MinIO (one time)
python scripts/setup_models.py medium

# 2. Run worker
rq worker stt_jobs --url redis://localhost:6379/0
```

### Example 2: Docker Development

```bash
# 1. Start infrastructure
docker-compose up -d mongodb redis minio

# 2. Upload models to MinIO
# Use MinIO web UI or client

# 3. Start worker (will auto-download model)
docker-compose up worker
```

### Example 3: Production Deployment

```yaml
# docker-compose.prod.yml
services:
  worker:
    image: your-registry/stt-worker:latest
    environment:
      MINIO_ENDPOINT: ${MINIO_ENDPOINT}
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY}
      MODEL_TO_DOWNLOAD: medium
    volumes:
      # Persist models across restarts
      - models_volume:/app/whisper/models
    deploy:
      replicas: 3

volumes:
  models_volume:
```

---

## Troubleshooting

### Issue 1: Model download fails

**Symptoms:**
```
Failed to download model: Model not found in MinIO
```

**Solutions:**
1. Check MinIO is running: `curl http://localhost:9000/minio/health/live`
2. Check model exists in MinIO:
   ```bash
   mc ls minio/stt-audio-files/whisper-models/
   ```
3. Verify MinIO credentials in `.env`
4. Upload model to MinIO:
   ```bash
   mc cp ggml-medium.bin minio/stt-audio-files/whisper-models/
   ```

### Issue 2: Model file corrupted

**Symptoms:**
```
Model file size mismatch: 500MB < 1500MB
```

**Solutions:**
1. Delete corrupted file:
   ```bash
   rm whisper/models/ggml-medium.bin
   ```
2. Re-download:
   ```bash
   python scripts/setup_models.py medium
   ```

### Issue 3: Docker build fails

**Symptoms:**
```
ERROR: whisper/models/ggml-medium.bin not found
```

**Solutions:**
- This is EXPECTED! Models should NOT be in Docker image
- Models will be downloaded at runtime
- Make sure entrypoint script is configured

### Issue 4: Out of disk space

**Symptoms:**
```
OSError: [Errno 28] No space left on device
```

**Solutions:**
1. Check disk space: `df -h`
2. Clean old models: `rm whisper/models/*.bin`
3. Download only needed model:
   ```bash
   export MODEL_TO_DOWNLOAD=tiny  # Smaller model
   ```

---

## üí° Best Practices

### 1. Model Selection

- **Development:** Use `tiny` or `base` (faster, smaller)
- **Production (Vietnamese):** Use `medium` (best balance)
- **Best quality:** Use `large` (slower, needs more RAM)

### 2. Caching

Models are cached after first download:
- Local: `whisper/models/`
- Docker volume: Persist across container restarts
- MinIO: Single source of truth

### 3. CI/CD

```yaml
# .github/workflows/deploy.yml
- name: Build Docker image
  run: docker build -f cmd/worker/Dockerfile -t worker:latest .
  # No need to include models in image!

- name: Deploy
  run: |
    # Models will be downloaded at runtime from MinIO
    docker-compose up -d
```

### 4. Monitoring

Check model status:
```bash
python scripts/setup_models.py
# Shows which models are available
```

---

## üìö Implementation Details

### Code Flow

```python
# worker/transcriber.py
class WhisperTranscriber:
    def transcribe(self, audio_path, model="medium"):
        # 1. Check if model exists
        model_downloader = get_model_downloader()
        
        # 2. Download from MinIO if missing
        model_path = model_downloader.ensure_model_exists(model)
        
        # 3. Run Whisper with model
        result = run_whisper(model_path, audio_path)
        return result
```

### Files Structure

```
.
‚îú‚îÄ‚îÄ worker/
‚îÇ   ‚îú‚îÄ‚îÄ model_downloader.py     # Model download logic
‚îÇ   ‚îî‚îÄ‚îÄ transcriber.py          # Uses model_downloader
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup_models.py         # Manual download script
‚îÇ   ‚îî‚îÄ‚îÄ docker-entrypoint.sh    # Docker startup script
‚îú‚îÄ‚îÄ whisper/
‚îÇ   ‚îú‚îÄ‚îÄ bin/                    # Whisper executable
‚îÇ   ‚îî‚îÄ‚îÄ models/                 # Models (gitignored)
‚îÇ       ‚îú‚îÄ‚îÄ .gitkeep
‚îÇ       ‚îî‚îÄ‚îÄ .model_cache.json   # Download cache
‚îî‚îÄ‚îÄ cmd/
    ‚îî‚îÄ‚îÄ worker/
        ‚îî‚îÄ‚îÄ Dockerfile          # Worker image (no models)
```

---

## Checklist

### For Developers:

- [ ] Upload models to MinIO
- [ ] Configure MinIO credentials in `.env`
- [ ] Run `python scripts/setup_models.py` to test download
- [ ] Verify model exists in `whisper/models/`

### For Docker Deployment:

- [ ] Build image WITHOUT models: `docker build -f cmd/worker/Dockerfile`
- [ ] Verify image size < 2GB
- [ ] Set `MINIO_*` environment variables
- [ ] Test model auto-download on first run
- [ ] (Optional) Use volume to persist models

### For Production:

- [ ] Upload all needed models to MinIO
- [ ] Configure model checksums (optional)
- [ ] Set up model caching strategy
- [ ] Monitor disk space on workers
- [ ] Document model update procedures

---

## üéâ Summary

**Benefits:**
- No large files in Git
- Smaller Docker images
- Automatic model management
- Easy to update models (just update MinIO)
- Models shared across deployments

**Tradeoffs:**
- First startup slower (download time)
- Requires MinIO setup
- Network dependency (for download)

**Solution:**
- Use Docker volumes to persist models
- Pre-download models in initialization phase
- Monitor MinIO availability

